{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf4e5f5b-d684-4671-9596-63d01c4b835f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# bootstrap_puzzles_02_update_word_states\n",
    "\n",
    "Using word data from past puzzles, updates the initial `silver.word_states` table based on the `bronze.word_decisions` records created after ingesting all of the past puzzles up to (including) 2025-06-23.\n",
    "\n",
    "This notebook performs the update all in one shot, rather than month by month. If this causes memory-related performance issues, we can refactor to run month by month. Another TODO will be to have the pipeline for the previous stage (which goes year/month by year/month) loop through all of the past years (2023, 2024, 2025) and run the notebook for each one, before proceeding to this stage.\n",
    "\n",
    "The `silver.word_states` table reflects the latest state of each word we are tracking, specifically:\n",
    "\n",
    "- `last_seen_on`: the date of the most recent explicit or implicit decision made about the word (can be null if the word has never been a possible puzzle answer)\n",
    "- `label`:\n",
    "    - `1.0` if the most recent decision explicitly included in the word in the official solution\n",
    "    - `0.0` if the most recent decision implicity rejected the word (it could be formed with the puzzle letters but was not included in the official solution)\n",
    "    - `null` if the word has never been a possible puzzle answer\n",
    "- `batch_id`: an identifier of the current puzzle or date range being processed, to support idempotent ops and redos\n",
    "- the `word`, `letter_set`, `frequency`, `embedding` columns from `bronze.words` for the given word.\n",
    "\n",
    "The process of updating the `silver.word_states` table is:\n",
    "\n",
    "- Read `bronze.word_decisions` into a data frame and use a window function to select the most recent decision about each word in the table. (For each word, find the decision with the latest `puzzle_date`.)\n",
    "- Rename `puzzle_date` to `last_seen_on`\n",
    "- Rename `accepted` to `label`\n",
    "- Add `batch_id` `\"bootstrap_puzzles_1\"` for this notebook\n",
    "- Identify new words and query/join their `letter_set`, `embedding`, and `frequency` columns so they can be inserted\n",
    "- Use Delta `MERGE INTO` semantics to update the latest decisions:\n",
    "    - merge into on the key match `source.word = target.word`\n",
    "    - `whenMatchedUpdate` on the condition `target.last_seen_on IS NULL OR source.last_seen_on >= target.last_seen_on`\n",
    "        - update the `last_seen_on`, `label`, and `batch_id` columns with the value in the source\n",
    "        - leave the `word`, `letter_set`, `frequency`, and `embedding` columns unchanged in the target (these are static properties of the word, not the decision). \n",
    "    - `whenNotMatchedInsert` for decisions about words that are not present in the target table (this is not expected in bootstrap)\n",
    "    - `whenNotMatchedBySourceDelete` to handle the case of reruns that must clean up rows from a previous run that should not have been added. The condition is `source.batch_id = target.batch_id`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e34bf0bc-bdcc-4cc7-a22a-3e2ccd37585a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./00_setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fa3c9b3-04b4-40a5-b1a3-05d816ef8df7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1368211b-d518-4912-b4d2-1624a8775ad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: parameterize\n",
    "_SOURCE_DB_NAME = \"bronze\"\n",
    "_SOURCE_DECISIONS_TABLE_NAME = \"word_decisions\"\n",
    "_SOURCE_WORDS_TABLE_NAME = \"words\"\n",
    "_TARGET_DB_NAME = \"silver\"\n",
    "_TARGET_TABLE_NAME = \"word_states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fa4ab84-29e3-4a8e-ba07-3db9e5f49d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the word decisions\n",
    "df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_DECISIONS_TABLE_NAME}\")\n",
    "print(f\"{df.count()} word_decisions in {_SOURCE_DB_NAME}.{_SOURCE_DECISIONS_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31d3a907-12f3-4519-9341-c8ec8c934aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_distinct = df.select(\"word\").distinct().count()\n",
    "print(f\"Number of distinct words in {_SOURCE_DB_NAME}.{_SOURCE_DECISIONS_TABLE_NAME}: {num_distinct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54224a8b-7f64-4688-b092-30edb2924f1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define window partitioned by word, ordered by puzzle_date\n",
    "window_spec = Window.partitionBy(\"word\").orderBy(F.col(\"puzzle_date\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26c7ae45-84bb-437a-bbd0-b717b94c79dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add row number to identify the most recent record\n",
    "# Then filter on the first (most recent record)\n",
    "filtered_df = df.withColumn(\"rn\", F.row_number().over(window_spec)) \\\n",
    "                .filter(F.col(\"rn\") == 1) \\\n",
    "                .drop(\"rn\")\n",
    "\n",
    "print(f\"Num records after filter: {filtered_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63231c99-db85-4199-aca0-a6dd2ffc3609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rename puzzle_date to last_seen_on\n",
    "# Add batch_id \"bootstrap_puzzles_1\" for this notebook\n",
    "BATCH_ID = \"bootstrap_puzzles_1\"\n",
    "source_df = filtered_df.withColumnRenamed(\"puzzle_date\", \"last_seen_on\") \\\n",
    "                       .withColumnRenamed(\"accepted\", \"label\") \\\n",
    "                       .withColumn(\"batch_id\", F.lit(BATCH_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25bf8a08-32d8-4d8d-a2c6-520bbbad7812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Identify which words in source_df won't be matched in the target table\n",
    "target_words_df = spark.sql(f\"SELECT word FROM {_TARGET_DB_NAME}.{_TARGET_TABLE_NAME}\")\n",
    "target_words = set([row.word for row in target_words_df.select(\"word\").collect()])\n",
    "\n",
    "source_words = set([row.word for row in source_df.select(\"word\").collect()])\n",
    "\n",
    "new_words = source_words - target_words\n",
    "print(f\"Found {len(target_words)} distinct words in target.\")\n",
    "print(f\"Found {len(source_words)} distinct words in source.\")\n",
    "print(f\"Found {len(new_words)} new words in source.\")\n",
    "if len(new_words) > 0:\n",
    "    print(f\"New words: {', '.join(sorted(new_words))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dff7c0bc-908f-4988-91a8-58c1ba230711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if len(new_words) > 0:\n",
    "    # Get embeddings and frequencies for new words, join to source_df\n",
    "    formatted_new_words = ', '.join([f\"'{word}'\" for word in sorted(new_words)])\n",
    "    query = f\"\"\"\n",
    "        SELECT word, letter_set, embedding, frequency\n",
    "        FROM {_SOURCE_DB_NAME}.{_SOURCE_WORDS_TABLE_NAME}\n",
    "        WHERE word IN ({formatted_new_words})\n",
    "    \"\"\"\n",
    "    new_words_df = spark.sql(query)\n",
    "    \n",
    "    # Join to enrich source_df with extra columns\n",
    "    source_df = source_df.join(new_words_df, on=\"word\", how=\"left\")\n",
    "else:\n",
    "    # No new words. Add NULL columns explicitly\n",
    "    source_df = source_df.withColumn(\"letter_set\", F.lit(None).cast(\"string\")) \\\n",
    "                         .withColumn(\"embedding\", F.lit(None).cast(\"array<float>\")) \\\n",
    "                         .withColumn(\"frequency\", F.lit(None).cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37d8c94e-6f6b-4b6a-a04d-c2ce39252498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_table = DeltaTable.forName(spark, f\"{_TARGET_DB_NAME}.{_TARGET_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65aea299-668f-41c8-b600-30827036ca3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use DeltaMergeBuilder for the merge operation\n",
    "merge_builder = target_table.alias(\"target\").merge(\n",
    "    source_df.alias(\"source\"),\n",
    "    \"target.word = source.word\"\n",
    ")\n",
    "\n",
    "# Define the merge logic\n",
    "merge_builder.whenMatchedUpdate(\n",
    "    condition=\"target.last_seen_on is null OR source.last_seen_on >= target.last_seen_on\",\n",
    "    set={\n",
    "        \"label\": \"source.label\",\n",
    "        \"last_seen_on\": \"source.last_seen_on\",\n",
    "        \"batch_id\": \"source.batch_id\"\n",
    "    }\n",
    ").whenNotMatchedInsert(\n",
    "    values={\n",
    "        \"word\": \"source.word\",\n",
    "        \"letter_set\": \"source.letter_set\",\n",
    "        \"frequency\": \"source.frequency\",\n",
    "        \"embedding\": \"source.embedding\",\n",
    "        \"last_seen_on\": \"source.last_seen_on\", \n",
    "        \"label\": \"source.label\",\n",
    "        \"batch_id\": \"source.batch_id\"\n",
    "    }\n",
    ").whenNotMatchedBySourceDelete(\n",
    "    condition=f\"target.batch_id = '{BATCH_ID}'\"\n",
    ").execute()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bootstrap_puzzles_02_update_word_states",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
