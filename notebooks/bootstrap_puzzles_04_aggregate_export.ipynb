{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7414e3-43d9-438d-87fe-cfd4617aec28",
   "metadata": {},
   "source": [
    "# bootstrap_puzzles_04_aggregate_export\n",
    "\n",
    "Groups the `gold.word_probabilities` table by letter_set, aggregating all words for that letter set in an array.\n",
    "\n",
    "This allows faster lookup of words by letter_set for inference (solving).\n",
    "\n",
    "Exports the aggregated table as a JSON file, tagging the file as `.latest.json` if it is the latest file in the exports dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291719c-ff5e-4ac3-bd12-05bfffdb52e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"./00_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24028762-976a-4c9f-972a-ef73d639ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from src.fileutils import get_local_path, get_all_files\n",
    "from src.constants import EXPORT_PATH, DATE_FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5765492-0fab-4e0b-9764-f993c2274f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parameterize\n",
    "_SOURCE_DB_NAME = \"gold\"\n",
    "_SOURCE_TABLE_NAME = \"word_probabilities\"\n",
    "_PUZZLE_DATE = \"2025-06-23\" # could be None for bootstrap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b95768-dd16-4b4a-8492-8b3634428597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1e66c-3ff0-475d-a641-2b59fb17f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {df.count()} records from {_SOURCE_DB_NAME}.{_SOURCE_TABLE_NAME}\")\n",
    "print(\"Labeled samples:\")\n",
    "df.filter(F.col(\"source\") == \"truth\").show(5)\n",
    "\n",
    "print(\"Predicted positive samples:\")\n",
    "df.filter(F.col(\"source\") == \"model\").sort(\"probability\", ascending=False).show(5)\n",
    "\n",
    "print(\"Predicted negative samples:\")\n",
    "df.filter(F.col(\"source\") == \"model\").sort(\"probability\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8461a3c-a5fd-41b9-890b-7cd737b2cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by letter_set\n",
    "result_df = df.groupBy(\"letter_set\").agg(\n",
    "    F.collect_list(\n",
    "        F.struct(\n",
    "            F.col(\"word\").alias(\"word\"),\n",
    "            F.col(\"probability\").alias(\"probability\"), \n",
    "            F.col(\"source\").alias(\"source\")\n",
    "        )\n",
    "    ).alias(\"data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b9094-3dd7-4b8d-a963-9b2c97647aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect rows and convert to dictionary (this should easily fit in memory)\n",
    "collected = result_df.collect()\n",
    "json_dict = {row.letter_set: [item.asDict() for item in row.data] for row in collected}\n",
    "\n",
    "print(f\"Converted to dictionary with {len(json_dict)} keys\")\n",
    "for letter_set, data in list(json_dict.items())[:5]:\n",
    "    print(f\"{letter_set}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666168e-e6ce-4b51-a414-69f2d6a26032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to export folder\n",
    "export_dir = Path(get_local_path(EXPORT_PATH))\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Find previous \"latest\" file and remove that tag from filename\n",
    "latest_data = get_all_files(EXPORT_PATH, [\".latest.json\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c519162-6185-4801-a19f-b0fd703da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how to save the export (as latest file or not)\n",
    "def parse_file_date(file_path: str) -> datetime:\n",
    "    file_name = Path(Path(file_path).stem).stem # drop .json, then drop .latest\n",
    "    file_date_str = file_name.split(\"_\")[-1]\n",
    "    file_date = datetime.strptime(file_date_str, DATE_FORMAT)\n",
    "    return file_date \n",
    "\n",
    "save_as_latest = False\n",
    "\n",
    "if len(latest_data) > 1:\n",
    "    raise Exception(f\"There should be only one .latest.json file, but found {len(latest_data)} files.\")\n",
    "\n",
    "if len(latest_data) > 0:\n",
    "    # find date of the latest file\n",
    "    latest_file_date = parse_file_date(latest_data[0])\n",
    "    current_date = datetime.strptime(_PUZZLE_DATE, DATE_FORMAT)\n",
    "\n",
    "    if current_date < latest_file_date:\n",
    "        print(f\"current date {current_date.strftime(DATE_FORMAT)} is earlier than latest file date {latest_file_date.strftime(DATE_FORMAT)}\")\n",
    "    else:\n",
    "        save_as_latest = True\n",
    "        print(f\"current date {current_date.strftime(DATE_FORMAT)} is most recent.\")\n",
    "        print(f\"removing latest tag from data_{latest_file_date.strftime(DATE_FORMAT)}.latest.json\")\n",
    "        old_file_path = Path(latest_data[0])\n",
    "        new_path = Path(str(old_file_path).replace(\".latest\", \"\"))\n",
    "        old_file_path.rename(new_path)\n",
    "        \n",
    "\n",
    "else:\n",
    "    save_as_latest = True\n",
    "    print(f\"No `.latest.json` files found in {get_local_file(EXPORT_PATH)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b805ad4-8509-4eb9-807e-1879aadff322",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_name = f\"data_{_PUZZLE_DATE}\"\n",
    "\n",
    "if save_as_latest:\n",
    "    export_path = export_dir / f\"{base_file_name}.latest.json\"\n",
    "    print(f\"Saving as latest file: {export_path}\")\n",
    "else:\n",
    "    export_path = export_dir / f\"{base_file_name}.json\"\n",
    "    print(f\"Saving as non-latest file: {export_path}\")\n",
    "\n",
    "# Dump json with minimal whitespace (cuts file size almost in half)\n",
    "with open(f\"{export_path}\", \"w\") as f:\n",
    "    json.dump(json_dict, f, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "print(f\"âœ… File saved as {export_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20048d12-d403-4ae5-be6b-9de3cff33f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
