{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae4dbd1-a279-4173-b3fb-9df8582359f9",
   "metadata": {},
   "source": [
    "# bootstrap_words_01_filter_add_words\n",
    "\n",
    "- read in external wordlist\n",
    "- filter out wordlist words that cannot be Spelling Bee solution words\n",
    "    - skip if < 4 chars long\n",
    "    - get letter_set, skip if len(letter_set) > 7\n",
    "    - append (word, letter_set, version) to rows\n",
    "- get all past puzzles from storage, find new solution words not in wordlist\n",
    "    -  add word, letter_set, and version = 2\n",
    "- for each word in puzzle_answer_words:\n",
    "    - version = 1 for words from external wordlist, = 2 for new words from puzzles \n",
    "    - add (word, letter_set, version) to rows\n",
    "- save to Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae69a8d-ba77-4fdd-b6d0-777b2c32e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./00_setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2366e9-cdda-4067-8692-44916c573bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: parameterize in pipeline\n",
    "_TARGET_DB_NAME = \"raw\"\n",
    "_TARGET_TABLE_NAME = \"words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0eabb-5257-48c7-a995-2baf5bf47417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wordutils import get_letter_set, filter_wordlist\n",
    "from src.constants import WORDLIST_PATH, RAW_WORDLIST_FILENAME, RAW_SOLUTIONS_PATH\n",
    "from src.fileutils import get_all_files, get_local_path, get_puzzle_by_path, word_file_to_set\n",
    "from src.sparkdbutils import create_db, create_unpartitioned_table\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad0d34-57f7-41a4-9ded-8a43cd9e3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the wordlist\n",
    "wordlist_words = filter_wordlist(word_file_to_set(f\"{WORDLIST_PATH}/{RAW_WORDLIST_FILENAME}\"))\n",
    "print(f\"ðŸ“‹ {len(wordlist_words)} words after filtering external wordlist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab610fb-e5e2-48bc-a41e-54fa887b5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add solution words from past puzzles that were not in the external wordlist\n",
    "# We do not need to filter out these words. If they were in a puzzle solution, they're valid.\n",
    "\n",
    "# get all puzzle paths\n",
    "puzzle_paths = get_all_files(RAW_SOLUTIONS_PATH, [\".json\"])\n",
    "puzzle_words = set()\n",
    "\n",
    "# load each puzzle and add to answer set\n",
    "for puzzle_path in puzzle_paths:\n",
    "    puzzle = get_puzzle_by_path(puzzle_path)\n",
    "    answers = puzzle[\"answers\"]\n",
    "    puzzle_words.update(answers)\n",
    "\n",
    "new_puzzle_words = puzzle_words - wordlist_words\n",
    "all_words = new_puzzle_words | set(wordlist_words)\n",
    "print(f\"ðŸ‘€ {len(new_puzzle_words)} new words found in past solutions: {', '.join(sorted(new_puzzle_words))}\")\n",
    "print(f\"ðŸ“‹ {len(all_words)} words total after adding new words from past puzzle answers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7236cde-0ea2-46f5-b09f-5b09db974edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the rows\n",
    "def get_wordlist_version(word: str) -> int:\n",
    "    if word in new_puzzle_words:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "rows = [(word, get_letter_set(word), get_wordlist_version(word)) for word in sorted(all_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec5ca4-ced6-4cd0-8749-b125fd2284f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total rows: {len(rows)}\")\n",
    "print(f\"new_puzzle_words rows: {len([row for row in rows if row[2] == 2])}\")\n",
    "print(f\"wordlist_words rows: {len([row for row in rows if row[2] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991abc5-ac1f-4d5c-bac3-6b54f0571af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"word\", StringType(), False),\n",
    "    StructField(\"letter_set\", StringType(), False),\n",
    "    StructField(\"version\", IntegerType(), False)\n",
    "])\n",
    "df = spark.createDataFrame(rows, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c758ca-d78f-433c-a68d-e3b9a4502fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally add date_added (all null for the bootstrap script)\n",
    "# In the future, this will show the puzzle date of a word that has been\n",
    "# added to the wordlist in a future puzzle\n",
    "df = df.withColumn(\"date_added\", F.lit(None).cast(\"date\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d6840-4ed3-480f-8038-db07a9f08a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_db(spark, _TARGET_DB_NAME)\n",
    "create_unpartitioned_table(spark, df, _TARGET_TABLE_NAME, _TARGET_DB_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
