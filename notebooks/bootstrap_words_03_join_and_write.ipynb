{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af084b94-f4cd-4355-9124-a9840d36cb7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./00_setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c42d3fab-1ae0-4bfc-99b7-d92bd4724679",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType\n",
    "import pyspark.sql.functions as F\n",
    "from src.sparkdbutils import create_db, create_unpartitioned_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1648efc0-7da2-41fc-ace8-0e7d31d82cf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: These should be pipeline parameters\n",
    "_SOURCE_DB_NAME = \"raw\"\n",
    "_SOURCE_WORDS_TABLE_NAME = \"words\"\n",
    "_SOURCE_EMBEDDINGS_TABLE_NAME = \"word_embeddings\"\n",
    "_SOURCE_FREQUENCIES_TABLE_NAME = \"word_frequencies\"\n",
    "_TARGET_DB_NAME = \"bronze\"\n",
    "_TARGET_TABLE_NAME = \"words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f509360f-020a-49f1-a44e-0f493db45e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read in tables to be merged\n",
    "words_df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_WORDS_TABLE_NAME}\")\n",
    "word_embeddings_df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_EMBEDDINGS_TABLE_NAME}\")\n",
    "word_frequencies_df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_FREQUENCIES_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fb6af54-91fa-4ddd-8dd0-b2499656c6ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform full outer joins to capture all possible words\n",
    "result_df = words_df.join(word_embeddings_df, on=\"word\", how=\"full_outer\") \\\n",
    "                    .join(word_frequencies_df, on=\"word\", how=\"full_outer\") \\\n",
    "                    .select(\"word\", \"letter_set\", \"date_added\", \"version\", \"frequency\", \"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c49fba53-3e0f-4fa2-9ca1-73771f7eeda3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Validation check\n",
    "# 1. Check for missing data patterns\n",
    "missing_analysis = result_df.select(\n",
    "    \"word\",\n",
    "    F.col(\"letter_set\").isNull().alias(\"missing_letter_set\"),\n",
    "    F.col(\"version\").isNull().alias(\"missing_version\"),\n",
    "    F.col(\"frequency\").isNull().alias(\"missing_frequency\"),\n",
    "    F.col(\"embedding\").isNull().alias(\"missing_embedding\")\n",
    ")\n",
    "\n",
    "# 2. Count missing data by source\n",
    "print(\"Missing data summary:\")\n",
    "missing_analysis.groupBy(\"missing_letter_set\", \n",
    "                         \"missing_version\",\n",
    "                         \"missing_frequency\",\n",
    "                         \"missing_embedding\") \\\n",
    "                 .count() \\\n",
    "                 .show()\n",
    "\n",
    "# 3. Find words that exist in some but not all DataFrames\n",
    "incomplete_words = result_df.filter(\n",
    "    (F.col(\"letter_set\").isNull()) | \n",
    "    (F.col(\"version\").isNull()) | \n",
    "    (F.col(\"frequency\").isNull()) | \n",
    "    (F.col(\"embedding\").isNull())\n",
    ")\n",
    "\n",
    "print(f\"Words with incomplete data: {incomplete_words.count()}\")\n",
    "if incomplete_words.count() > 0:\n",
    "    print(\"Examples of incomplete words:\")\n",
    "    incomplete_words.show(10)\n",
    "    raise Exception(\"Rows above have incomplete data.\")\n",
    "\n",
    "# 4. Verify your assumption about identical word sets\n",
    "print(\"Row count comparison:\")\n",
    "words_df_count = words_df.count()\n",
    "word_embeddings_df_count = word_embeddings_df.count()\n",
    "word_frequencies_df_count = word_frequencies_df.count()\n",
    "result_df_count = result_df.count()\n",
    "print(f\"words_df: {words_df_count}\")\n",
    "print(f\"word_embeddings_df: {word_embeddings_df_count}\")\n",
    "print(f\"word_frequencies_df: {word_frequencies_df_count}\")\n",
    "print(f\"Full outer join: {result_df_count}\")\n",
    "\n",
    "all_counts = set([words_df_count, \n",
    "                  word_embeddings_df_count,\n",
    "                  word_frequencies_df_count,\n",
    "                  result_df_count])\n",
    "\n",
    "if len(all_counts) > 1:\n",
    "    raise Exception(\"Row counts do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fce0e1e-2bcc-4c81-8078-57f5e1649816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_db(spark, _TARGET_DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79753afa-2df1-47d1-b3a6-3d65d5f1606a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_unpartitioned_table(spark, result_df, _TARGET_TABLE_NAME, _TARGET_DB_NAME)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bootstrap_words_03_join_and_write",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
