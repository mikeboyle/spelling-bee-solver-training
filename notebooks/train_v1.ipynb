{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c41cbb-1b2a-46e7-bdd0-ad08a863122e",
   "metadata": {},
   "source": [
    "# train_v1\n",
    "\n",
    "Uses the labeled subset `silver.word_states` data for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6491a8-2869-4a73-8309-1c8494a8c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run './00_setup.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c74716-5a93-4106-8898-437f3e7ded45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainutils import convert_df_to_features_v1, evaluate_thresholds\n",
    "from src.models.HybridFrequencyBinaryClassifier import HybridFrequencyBinaryClassifier\n",
    "from src.constants import TRAINED_MODELS_PATH\n",
    "from src.fileutils import get_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b29516-5690-42cc-9c9e-1090af1b4980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "import joblib\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import pyspark.sql.functions as F\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f7a5a-f75f-4b97-afec-36880db28392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants - TODO: Keep here or move?\n",
    "C = 0.10\n",
    "N_COMPONENTS = 300\n",
    "\n",
    "# TODO: Notebook parameters\n",
    "_SOURCE_DB_NAME = \"silver\"\n",
    "_SOURCE_TABLE_NAME = \"word_states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286c425-30d0-4a3b-9f05-256582be9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_for_training(x_train, x_test, n_components=50):\n",
    "    # Separate frequency and embeddings\n",
    "    x_train_freq = x_train[:, :1]\n",
    "    x_train_emb = x_train[:, 1:]\n",
    "\n",
    "    x_test_freq = x_test[:, :1]\n",
    "    x_test_emb = x_test[:, 1:]\n",
    "    \n",
    "    # Apply Truncated SVD to embeddings\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=0)\n",
    "    x_train_emb_reduced = svd.fit_transform(x_train_emb)\n",
    "    x_test_emb_reduced = svd.transform(x_test_emb)\n",
    "\n",
    "    # Recombine with frequency\n",
    "    x_train_reduced = np.hstack([x_train_freq, x_train_emb_reduced])\n",
    "    x_test_reduced = np.hstack([x_test_freq, x_test_emb_reduced])\n",
    "\n",
    "    return x_train_reduced, x_test_reduced, svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118abe41-d511-4efa-968c-84c609141132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_bin_boundaries(freq):\n",
    "    # Find optimized bin boundaries\n",
    "    # Choose 20 candidate thresholds and split into low and high ranges\n",
    "    quantiles = np.linspace(0.05, 0.95, 20)\n",
    "    candidates = np.quantile(freq, quantiles)\n",
    "    \n",
    "    # Split into low and high ranges, avoiding complete overlap\n",
    "    low_range = candidates[:10]   # 5th to 50th percentile\n",
    "    high_range = candidates[10:]  # 50th to 95th percentile\n",
    "    \n",
    "    thresholds, _ = evaluate_thresholds(freq, y, low_range, high_range)\n",
    "    low_threshold, high_threshold = thresholds\n",
    "    \n",
    "    if low_threshold is None or high_threshold is None:\n",
    "        # substitue hard coded values\n",
    "        low_threshold = 1.68\n",
    "        high_threshold = 4.72\n",
    "\n",
    "    return low_threshold, high_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04616fc-5e62-4d2b-93fc-235bf13d0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train_reduced, y_train, freq, words):\n",
    "    \n",
    "    low_threshold, high_threshold = get_frequency_bin_boundaries(freq)\n",
    "\n",
    "    # Initialize model and train\n",
    "    low_freq_clf = GaussianNB()\n",
    "    mid_freq_clf = LogisticRegression(class_weight=\"balanced\", max_iter=1000, C=C)\n",
    "    high_freq_clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        class_weight='balanced',\n",
    "        random_state=0\n",
    "    )\n",
    "              \n",
    "    clf = HybridFrequencyBinaryClassifier(\n",
    "        low_mid_threshold=low_threshold,\n",
    "        mid_high_threshold=high_threshold,\n",
    "        low_freq_model=low_freq_clf,\n",
    "        mid_freq_model=mid_freq_clf,\n",
    "        high_freq_model=high_freq_clf\n",
    "    )\n",
    "    \n",
    "    clf.fit(x_train_reduced, y_train)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9e269-b9a2-433b-a973-f7c266d69195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_TABLE_NAME} WHERE label is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab497f28-00b4-4f49-9ab9-c722ea876951",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {df.count()} training samples from {_SOURCE_DB_NAME}.{_SOURCE_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeedd1-3fe6-45f0-ab52-280c931bf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frequencies to log frequencies\n",
    "df = df.withColumn(\"log_frequency\", F.log10(F.col(\"frequency\") + 1))\n",
    "\n",
    "# Concatenate log_frequency + features into single feature vector\n",
    "final_df = convert_df_to_features_v1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c08946-18db-417a-93c6-7ba273cb0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas df to get X and y\n",
    "pandas_df = final_df.toPandas()\n",
    "X = pandas_df['features'].tolist()  # Convert Series of arrays to list of arrays\n",
    "y = pandas_df['label'].tolist()\n",
    "words = [row.word for row in df.select(\"word\").collect()]\n",
    "freq = np.array([row.log_frequency for row in df.select(\"log_frequency\").collect()])\n",
    "\n",
    "X = np.array(pandas_df['features'].tolist())  # Shape: (n_samples, 769)\n",
    "y = np.array(pandas_df['label'].tolist())     # Shape: (n_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f42f8-d157-4e25-a7e3-16d7997e3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the test and train split and decompose the X data\n",
    "x_train, x_test, y_train, y_test, words_train, words_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    words, \n",
    "    test_size=0.33, \n",
    "    random_state=0, \n",
    "    stratify=y\n",
    ")\n",
    "    \n",
    "x_train_reduced, x_test_reduced, svd = decompose_for_training(x_train, x_test, N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b702640-c246-4f86-8bb4-2e6cef25e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "clf = train(x_train_reduced, y_train, freq, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfdac8-911a-451e-8152-93cc78540347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the results\n",
    "y_pred = clf.predict(x_test_reduced)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "y_proba = clf.predict_proba(x_test_reduced)\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_proba[:, 1])\n",
    "\n",
    "print(f\"confusion matrix:\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print(f\"accuracy: {acc}, f1: {f1}, AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c4d4d-87d8-40ab-b435-05af1d9a02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"word\": words_test,\n",
    "    \"frequency\": x_test_reduced[:, 0],\n",
    "    \"true\": y_test,\n",
    "    \"pred\": y_pred\n",
    "})\n",
    "\n",
    "false_negatives = results[(results[\"true\"] == 1) & (results[\"pred\"] == 0)]\n",
    "true_negatives = results[(results[\"true\"] == 0) & (results[\"pred\"] == 0)]\n",
    "false_positives = results[(results[\"true\"] == 0) & (results[\"pred\"] == 1)]\n",
    "true_positives = results[(results[\"true\"] == 1) & (results[\"pred\"] == 1)]\n",
    "print(f\"false negatives\\n{false_negatives.head()}\")\n",
    "print(f\"true negatives\\n{true_negatives.head()}\")\n",
    "print(f\"false positives\\n{false_positives.head()}\")\n",
    "print(f\"true positives\\n{true_positives.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a9664-511a-49e9-9f24-27ba2c6d9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and svd to joblib\n",
    "model = {\n",
    "    \"svd\": svd,\n",
    "    \"clf\": clf,\n",
    "}\n",
    "\n",
    "model_file = f\"{TRAINED_MODELS_PATH}/model_v1.joblib\"\n",
    "model_path = Path(get_local_path(model_file))\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(model_path, \"wb\") as f_model:\n",
    "    joblib.dump(model, f_model, protocol=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
