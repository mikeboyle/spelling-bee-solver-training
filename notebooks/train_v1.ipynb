{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "142da828-8e35-4741-9bbf-f034a3811dbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# train_v1\n",
    "\n",
    "Uses the labeled subset `silver.word_states` data for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a495f0c-2e16-45e2-885b-bc41ce23a564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./00_setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d974a3-c59f-4617-985a-1bc63439e238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.trainutils import convert_df_to_features_v1, evaluate_thresholds\n",
    "from src.models.HybridFrequencyBinaryClassifier import HybridFrequencyBinaryClassifier\n",
    "from src.constants import TRAINED_MODELS_PATH\n",
    "from src.fileutils import get_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b97f3b4-d0f0-484a-8768-075ec3492206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "import joblib\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import pyspark.sql.functions as F\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f453a6c-a139-42f4-991d-c1f0eea4c7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Constants - TODO: Keep here or move?\n",
    "C = 0.10\n",
    "N_COMPONENTS = 300\n",
    "\n",
    "# TODO: Notebook parameters\n",
    "_SOURCE_DB_NAME = \"silver\"\n",
    "_SOURCE_TABLE_NAME = \"word_states\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b08ab84-d353-4bfb-9610-d24bce31fb13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def decompose_for_training(x_train, x_test, n_components=50):\n",
    "    # Separate frequency and embeddings\n",
    "    x_train_freq = x_train[:, :1]\n",
    "    x_train_emb = x_train[:, 1:]\n",
    "\n",
    "    x_test_freq = x_test[:, :1]\n",
    "    x_test_emb = x_test[:, 1:]\n",
    "    \n",
    "    # Apply Truncated SVD to embeddings\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=0)\n",
    "    x_train_emb_reduced = svd.fit_transform(x_train_emb)\n",
    "    x_test_emb_reduced = svd.transform(x_test_emb)\n",
    "\n",
    "    # Recombine with frequency\n",
    "    x_train_reduced = np.hstack([x_train_freq, x_train_emb_reduced])\n",
    "    x_test_reduced = np.hstack([x_test_freq, x_test_emb_reduced])\n",
    "\n",
    "    return x_train_reduced, x_test_reduced, svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fe99424-ccf0-4022-8eb3-b66e172cb8c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_frequency_bin_boundaries(freq):\n",
    "    # Find optimized bin boundaries\n",
    "    # Choose 20 candidate thresholds and split into low and high ranges\n",
    "    quantiles = np.linspace(0.05, 0.95, 20)\n",
    "    candidates = np.quantile(freq, quantiles)\n",
    "    \n",
    "    # Split into low and high ranges, avoiding complete overlap\n",
    "    low_range = candidates[:10]   # 5th to 50th percentile\n",
    "    high_range = candidates[10:]  # 50th to 95th percentile\n",
    "    \n",
    "    thresholds, _ = evaluate_thresholds(freq, y, low_range, high_range)\n",
    "    low_threshold, high_threshold = thresholds\n",
    "    \n",
    "    if low_threshold is None or high_threshold is None:\n",
    "        # substitue hard coded values\n",
    "        low_threshold = 1.68\n",
    "        high_threshold = 4.72\n",
    "\n",
    "    return low_threshold, high_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262f710e-bfc1-49a5-a6bb-9964dbd8e890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train_reduced, y_train, freq, words):\n",
    "    \n",
    "    low_threshold, high_threshold = get_frequency_bin_boundaries(freq)\n",
    "\n",
    "    # Initialize model and train\n",
    "    low_freq_clf = GaussianNB()\n",
    "    mid_freq_clf = LogisticRegression(class_weight=\"balanced\",\n",
    "        max_iter=1000,\n",
    "        C=C,\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    high_freq_clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        class_weight='balanced',\n",
    "        random_state=0,\n",
    "        n_jobs=1\n",
    "    )\n",
    "              \n",
    "    clf = HybridFrequencyBinaryClassifier(\n",
    "        low_mid_threshold=low_threshold,\n",
    "        mid_high_threshold=high_threshold,\n",
    "        low_freq_model=low_freq_clf,\n",
    "        mid_freq_model=mid_freq_clf,\n",
    "        high_freq_model=high_freq_clf\n",
    "    )\n",
    "    \n",
    "    clf.fit(x_train_reduced, y_train)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff042d45-e8bf-49ef-9dfa-a005db6658ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"SELECT * FROM {_SOURCE_DB_NAME}.{_SOURCE_TABLE_NAME} WHERE label is not NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec11bcbc-31e5-43f8-b0c8-17b80bf2a978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Loaded {df.count()} training samples from {_SOURCE_DB_NAME}.{_SOURCE_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b37a44-ab4e-4a1c-b53f-bfe98f94938c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert frequencies to log frequencies\n",
    "df = df.withColumn(\"log_frequency\", F.log10(F.col(\"frequency\") + 1))\n",
    "\n",
    "# Concatenate log_frequency + features into single feature vector\n",
    "final_df = convert_df_to_features_v1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb4616f-c7b8-4906-843f-05d5e2c825f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas df to get X and y\n",
    "pandas_df = final_df.toPandas()\n",
    "X = pandas_df['features'].tolist()  # Convert Series of arrays to list of arrays\n",
    "y = pandas_df['label'].tolist()\n",
    "words = [row.word for row in df.select(\"word\").collect()]\n",
    "freq = np.array([row.log_frequency for row in df.select(\"log_frequency\").collect()])\n",
    "\n",
    "X = np.array(pandas_df['features'].tolist())  # Shape: (n_samples, 769)\n",
    "y = np.array(pandas_df['label'].tolist())     # Shape: (n_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34e6e625-efd4-4b5a-babe-2581c1e380c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the test and train split and decompose the X data\n",
    "x_train, x_test, y_train, y_test, words_train, words_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    words, \n",
    "    test_size=0.33, \n",
    "    random_state=0, \n",
    "    stratify=y\n",
    ")\n",
    "    \n",
    "x_train_reduced, x_test_reduced, svd = decompose_for_training(x_train, x_test, N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f222f12-48af-4b56-93d9-0ed7d369a218",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "clf = train(x_train_reduced, y_train, freq, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8567e85-dd74-4a8c-b3b8-84c4fc8bd1fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Score the results\n",
    "y_pred = clf.predict(x_test_reduced)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
    "y_proba = clf.predict_proba(x_test_reduced)\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_proba[:, 1])\n",
    "\n",
    "print(f\"confusion matrix:\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print(f\"accuracy: {acc}, f1: {f1}, AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3edef5e-6e0c-4ef0-a8ae-65dfed075491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"word\": words_test,\n",
    "    \"frequency\": x_test_reduced[:, 0],\n",
    "    \"true\": y_test,\n",
    "    \"pred\": y_pred\n",
    "})\n",
    "\n",
    "false_negatives = results[(results[\"true\"] == 1) & (results[\"pred\"] == 0)]\n",
    "true_negatives = results[(results[\"true\"] == 0) & (results[\"pred\"] == 0)]\n",
    "false_positives = results[(results[\"true\"] == 0) & (results[\"pred\"] == 1)]\n",
    "true_positives = results[(results[\"true\"] == 1) & (results[\"pred\"] == 1)]\n",
    "print(f\"false negatives\\n{false_negatives.head()}\")\n",
    "print(f\"true negatives\\n{true_negatives.head()}\")\n",
    "print(f\"false positives\\n{false_positives.head()}\")\n",
    "print(f\"true positives\\n{true_positives.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84554fa7-9b1f-4741-a1d9-c9f041efbd5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save model and svd to joblib\n",
    "model = {\n",
    "    \"svd\": svd,\n",
    "    \"clf\": clf,\n",
    "}\n",
    "\n",
    "model_file = f\"{TRAINED_MODELS_PATH}/model_v1.joblib\"\n",
    "model_path = Path(get_local_path(model_file))\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(model_path, \"wb\") as f_model:\n",
    "    joblib.dump(model, f_model, protocol=None)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train_v1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
