{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4200ec87-f122-4971-b060-a015e23c44ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Backfill: transform_word_decisions\n",
    "\n",
    "Part of historical backfill pipeline\n",
    "\n",
    "- One backfill pipeline run per year\n",
    "- Work in batches of one month\n",
    "- For each month:\n",
    "    - Get the filepaths of puzzles for that month\n",
    "    - Transform each puzzle into `word_decisions` table rows\n",
    "    - write to the bronze table\n",
    "    - perform validation checks and audit logs before and after each write op\n",
    "\n",
    "## âš ï¸ Not working locally? âš ï¸\n",
    "\n",
    "To run this notebook locally, edit the first code cell:\n",
    "\n",
    "Change:  \n",
    "`%run \"./00_setup\"`  \n",
    "To:  \n",
    "`%run \"./00_setup.ipynb\"`\n",
    "\n",
    "ðŸ‘‰ _Please **do not commit** this change â€” it's only for local execution._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e926cf0-63f8-4b5c-adec-c78252d241bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./00_setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "915bcbd3-0049-4601-9b27-7e8448ffbe0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * \n",
    "import pyspark.sql.functions as F\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b896b40-c5eb-4f38-8398-8fc5f8792c8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.sparkdbutils import create_db, write_to_table_replace_where\n",
    "from src.fileutils import get_latest_wordlist, word_file_to_set, get_puzzle_paths\n",
    "from src.wordutils import get_letter_set_map, transform_puzzle_to_word_decisions_by_path\n",
    "from src.bronzeutils import rows_to_word_decisions_df, WORD_DECISIONS_PARTITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cedea94-ee3f-4d61-8ba2-25c0924550ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wordlist_filename, wordlist_version = get_latest_wordlist()\n",
    "wordlist = word_file_to_set(wordlist_filename)\n",
    "letter_set_map = get_letter_set_map(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc497efc-94cd-4697-828f-325246a59076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_month(year: int, month: int) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns word_decision rows for all puzzles in the given year/month\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    puzzle_paths = get_puzzle_paths(year, month)\n",
    "    for puzzle_path in sorted(puzzle_paths):\n",
    "        curr_rows = transform_puzzle_to_word_decisions_by_path(puzzle_path,\n",
    "                                                               wordlist,\n",
    "                                                               letter_set_map,\n",
    "                                                               wordlist_version)\n",
    "        rows.extend(curr_rows)\n",
    "\n",
    "    return rows_to_word_decisions_df(rows, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b13f3f61-27f1-4c80-8f3b-1fdf3a81dfbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Parameterize _YEAR, _TARGET_DB_NAME, _TABLE_NAME\n",
    "_YEAR = 0000\n",
    "_TARGET_DB_NAME = \"bronze\"\n",
    "_TABLE_NAME = \"word_decisions\"\n",
    "create_db(spark, _TARGET_DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08936674-dd91-4371-b8b0-6a53392a325e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_rows = 0\n",
    "\n",
    "for month in range(1, 13):\n",
    "    print(f\"Processing year {_YEAR}, month {month}...\")\n",
    "    df = process_month(_YEAR, month)\n",
    "    \n",
    "    curr_count = df.count()\n",
    "    total_rows += curr_count\n",
    "    print(f\"Writing {curr_count} rows to {_TARGET_DB_NAME}.{_TABLE_NAME}\")\n",
    "    replace_where_dict = {\n",
    "        \"year\": _YEAR,\n",
    "        \"month\": month,\n",
    "    }\n",
    "    write_to_table_replace_where(spark,\n",
    "                   df,\n",
    "                   _TARGET_DB_NAME,\n",
    "                   _TABLE_NAME,\n",
    "                   replace_where_dict,\n",
    "                   WORD_DECISIONS_PARTITIONS)\n",
    "\n",
    "    # TODO: validation, audit log, etc.\n",
    "print(f\"{total_rows} written in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a05db5ca-7a60-42f5-bbdb-9f6b28710ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"SELECT * FROM bronze.word_decisions\")\n",
    "print(f\"{df2.count()} total rows in table\")\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44e81ee-1d4a-4ef8-938c-e99d409a4cfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.select([\"year\", \"month\"]).distinct().sort([\"year\", \"month\",]).show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3169ec07-5f98-4757-a90f-f9ee6e4ec293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_words = df2.filter(df2.was_in_wordlist == False).select(\"word\").distinct().sort(\"word\")\n",
    "print(f\"{new_words.count()} words not found in external wordlist\")\n",
    "new_words.show(new_words.count())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_word_decisions_backfill",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
