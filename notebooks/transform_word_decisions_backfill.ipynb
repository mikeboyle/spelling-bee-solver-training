{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b16803-03af-4363-b95b-9b29f2c8d48a",
   "metadata": {},
   "source": [
    "# Backfill: transform_word_decisions\n",
    "\n",
    "Part of historical backfill pipeline\n",
    "\n",
    "- One backfill pipeline run per year\n",
    "- Work in batches of one month\n",
    "- For each month:\n",
    "    - Get the filepaths of puzzles for that month\n",
    "    - Transform each puzzle into `word_decisions` table rows\n",
    "    - write to the bronze table\n",
    "    - perform validation checks and audit logs before and after each write op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162832ff-4821-46a3-9ed8-f249f4b97a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./00_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7751ea0-964f-472b-a4ab-828f00c4862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * \n",
    "import pyspark.sql.functions as F\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a8663-694a-415f-9d01-1d91d41303ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sparkdbutils import get_or_create_db, write_to_table\n",
    "from src.fileutils import get_latest_wordlist, word_file_to_set, get_puzzle_paths\n",
    "from src.wordutils import get_letter_set_map, transform_puzzle_to_word_decisions_by_path\n",
    "from src.bronzeutils import rows_to_word_decisions_df, WORD_DECISIONS_PARTITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b7417-a61b-40d0-be91-f67033b12b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_filename, wordlist_version = get_latest_wordlist()\n",
    "wordlist = word_file_to_set(wordlist_filename)\n",
    "letter_set_map = get_letter_set_map(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4626c33-5f53-44c4-865b-acbc0c24af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_month(year: int, month: int) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns word_decision rows for all puzzles in the given year/month\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    puzzle_paths = get_puzzle_paths(year, month)\n",
    "    for puzzle_path in sorted(puzzle_paths):\n",
    "        curr_rows = transform_puzzle_to_word_decisions_by_path(puzzle_path,\n",
    "                                                               wordlist,\n",
    "                                                               letter_set_map,\n",
    "                                                               wordlist_version)\n",
    "        rows.extend(curr_rows)\n",
    "\n",
    "    return rows_to_word_decisions_df(rows, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e335754-aaa6-45be-b46d-5578c6c1c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parameterize _YEAR, _TARGET_DB_NAME, _TABLE_NAME\n",
    "_YEAR = \"YYYY\"\n",
    "_TARGET_DB_NAME = \"bronze\"\n",
    "_TABLE_NAME = \"word_decisions\"\n",
    "get_or_create_db(spark, _TARGET_DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19978db4-864a-4b44-bd1a-759427f29d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = 0\n",
    "\n",
    "for month in range(1, 13):\n",
    "    print(f\"Processing year {_YEAR}, month {month}...\")\n",
    "    df = process_month(_YEAR, month)\n",
    "    \n",
    "    curr_count = df.count()\n",
    "    total_rows += curr_count\n",
    "    print(f\"Writing {curr_count} rows to {_TARGET_DB_NAME}.{_TABLE_NAME}\")\n",
    "    replace_where_dict = {\n",
    "        \"year\": _YEAR,\n",
    "        \"month\": month,\n",
    "    }\n",
    "    write_to_table(spark,\n",
    "                   df,\n",
    "                   _TARGET_DB_NAME,\n",
    "                   _TABLE_NAME,\n",
    "                   replace_where_dict,\n",
    "                   WORD_DECISIONS_PARTITIONS)\n",
    "\n",
    "    # TODO: validation, audit log, etc.\n",
    "print(f\"{total_rows} written in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d494a-fe9e-4789-8250-c6bf4d99a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"SELECT * FROM bronze.word_decisions\")\n",
    "print(f\"{df2.count()} total rows in table\")\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a51af9-49f8-479c-8809-32fd0da10494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select([\"year\", \"month\"]).distinct().sort([\"year\", \"month\",]).show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f7b81-4968-4545-803d-f2278aebcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = df2.filter(df2.was_in_wordlist == False).select(\"word\").distinct().sort(\"word\")\n",
    "print(f\"{new_words.count()} words not found in external wordlist\")\n",
    "new_words.show(new_words.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
